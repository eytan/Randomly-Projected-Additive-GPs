{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import rp_experiments\n",
    "import training_routines\n",
    "import pandas as pd\n",
    "import gpytorch\n",
    "import json\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py:184: RuntimeWarning: Mean of empty slice.\n",
      "  ma[i] = losses[i-patience+1:i+1].mean()\n",
      "/home/ian/miniconda3/envs/GPyTorchEnv2/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/ian/gpytorch/gpytorch/models/exact_gp.py:190: UserWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  \"The input matches the stored training data. Did you forget to call model.train()?\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 15:02:49.089445, fold=0, rep=0, eta=0d 0h 4m 6s \n",
      "{'fold': 0, 'repeat': 0, 'n': 23, 'd': 2, 'mse': 0.539741039276123, 'train_time': 12.968127058004029, 'prior_train_nmll': 1.5086475610733032, 'train_nll': 21.77501678466797, 'test_nll': 3.524848222732544, 'train_mse': 0.42348822951316833, 'state_dict_file': 'model_state_dict_5481701310660915877.pkl'}\n",
      "2019-03-16 15:03:00.186879, fold=0, rep=1, eta=0d 0h 3m 36s \n",
      "{'fold': 0, 'repeat': 1, 'n': 23, 'd': 2, 'mse': 0.19903410971164703, 'train_time': 11.097243868978694, 'prior_train_nmll': 1.504563570022583, 'train_nll': 20.27582550048828, 'test_nll': 2.9719150066375732, 'train_mse': 0.3344864249229431, 'state_dict_file': 'model_state_dict_-2282922694711208705.pkl'}\n",
      "2019-03-16 15:03:09.763946, fold=1, rep=0, eta=0d 0h 3m 10s \n",
      "{'fold': 1, 'repeat': 0, 'n': 23, 'd': 2, 'mse': 0.5020298361778259, 'train_time': 9.572137424955145, 'prior_train_nmll': 1.4897948503494263, 'train_nll': 11.776873588562012, 'test_nll': 3.2702648639678955, 'train_mse': 0.09221820533275604, 'state_dict_file': 'model_state_dict_7033948814869623064.pkl'}\n",
      "2019-03-16 15:03:21.731063, fold=1, rep=1, eta=0d 0h 3m 2s \n",
      "{'fold': 1, 'repeat': 1, 'n': 23, 'd': 2, 'mse': 0.34153851866722107, 'train_time': 11.966880692983977, 'prior_train_nmll': 1.470295786857605, 'train_nll': 12.658514022827148, 'test_nll': 2.866973876953125, 'train_mse': 0.11608357727527618, 'state_dict_file': 'model_state_dict_1226232652619179556.pkl'}\n",
      "2019-03-16 15:03:31.400950, fold=2, rep=0, eta=0d 0h 2m 45s \n",
      "{'fold': 2, 'repeat': 0, 'n': 23, 'd': 2, 'mse': 0.875917911529541, 'train_time': 9.665900059044361, 'prior_train_nmll': 1.4607353210449219, 'train_nll': 18.231178283691406, 'test_nll': 4.275941848754883, 'train_mse': 0.2515183687210083, 'state_dict_file': 'model_state_dict_4183148556585905819.pkl'}\n",
      "2019-03-16 15:03:40.961736, fold=2, rep=1, eta=0d 0h 2m 31s \n",
      "{'fold': 2, 'repeat': 1, 'n': 23, 'd': 2, 'mse': 0.7476749420166016, 'train_time': 9.560563714941964, 'prior_train_nmll': 1.4689013957977295, 'train_nll': 19.264476776123047, 'test_nll': 3.934051275253296, 'train_mse': 0.2995811104774475, 'state_dict_file': 'model_state_dict_5635698873257492025.pkl'}\n",
      "2019-03-16 15:03:53.292640, fold=3, rep=0, eta=0d 0h 2m 23s \n",
      "{'fold': 3, 'repeat': 0, 'n': 23, 'd': 2, 'mse': 1.9047565460205078, 'train_time': 12.325028069899417, 'prior_train_nmll': 1.411368727684021, 'train_nll': 6.062746047973633, 'test_nll': 5.6391520500183105, 'train_mse': 0.03723924234509468, 'state_dict_file': 'model_state_dict_-2090655822804753852.pkl'}\n",
      "2019-03-16 15:04:07.558766, fold=3, rep=1, eta=0d 0h 2m 17s \n",
      "{'fold': 3, 'repeat': 1, 'n': 23, 'd': 2, 'mse': 1.9637326002120972, 'train_time': 14.265895630931482, 'prior_train_nmll': 1.3612067699432373, 'train_nll': 14.118461608886719, 'test_nll': 6.173206329345703, 'train_mse': 0.14822739362716675, 'state_dict_file': 'model_state_dict_-139825982313006691.pkl'}\n",
      "2019-03-16 15:04:12.112347, fold=4, rep=0, eta=0d 0h 1m 57s \n",
      "{'fold': 4, 'repeat': 0, 'n': 23, 'd': 2, 'mse': 3.1678683757781982, 'train_time': 4.548558574984781, 'prior_train_nmll': 1.1562132835388184, 'train_nll': 0.20898056030273438, 'test_nll': 29.2530574798584, 'train_mse': 0.02061283215880394, 'state_dict_file': 'model_state_dict_-9022249589547738386.pkl'}\n",
      "2019-03-16 15:04:16.686932, fold=4, rep=1, eta=0d 0h 1m 40s \n",
      "{'fold': 4, 'repeat': 1, 'n': 23, 'd': 2, 'mse': 3.7492246627807617, 'train_time': 4.574275991995819, 'prior_train_nmll': 1.0731585025787354, 'train_nll': -1.7145805358886719, 'test_nll': 50.182594299316406, 'train_mse': 0.017721785232424736, 'state_dict_file': 'model_state_dict_-1101573603144495157.pkl'}\n",
      "2019-03-16 15:04:24.021874, fold=5, rep=0, eta=0d 0h 1m 28s \n",
      "{'fold': 5, 'repeat': 0, 'n': 23, 'd': 2, 'mse': 0.220115527510643, 'train_time': 7.330599689972587, 'prior_train_nmll': 1.520897626876831, 'train_nll': 18.10640525817871, 'test_nll': 2.7005624771118164, 'train_mse': 0.23199263215065002, 'state_dict_file': 'model_state_dict_-7117110953417941374.pkl'}\n",
      "2019-03-16 15:04:32.465532, fold=5, rep=1, eta=0d 0h 1m 17s \n",
      "{'fold': 5, 'repeat': 1, 'n': 23, 'd': 2, 'mse': 0.21240663528442383, 'train_time': 8.443434390006587, 'prior_train_nmll': 1.4965742826461792, 'train_nll': 18.584548950195312, 'test_nll': 2.634784698486328, 'train_mse': 0.266084760427475, 'state_dict_file': 'model_state_dict_6151956646786945680.pkl'}\n",
      "2019-03-16 15:04:39.849303, fold=6, rep=0, eta=0d 0h 1m 6s \n",
      "{'fold': 6, 'repeat': 0, 'n': 23, 'd': 2, 'mse': 1.1073025465011597, 'train_time': 7.378614210989326, 'prior_train_nmll': 1.4791359901428223, 'train_nll': 14.548095703125, 'test_nll': 4.660927772521973, 'train_mse': 0.1484179049730301, 'state_dict_file': 'model_state_dict_-2583685294879070532.pkl'}\n",
      "2019-03-16 15:04:47.017456, fold=6, rep=1, eta=0d 0h 0m 56s \n",
      "{'fold': 6, 'repeat': 1, 'n': 23, 'd': 2, 'mse': 0.7891602516174316, 'train_time': 7.167929287999868, 'prior_train_nmll': 1.474351167678833, 'train_nll': 20.349529266357422, 'test_nll': 3.9449942111968994, 'train_mse': 0.35370272397994995, 'state_dict_file': 'model_state_dict_-4830500014261765795.pkl'}\n",
      "2019-03-16 15:05:01.094708, fold=7, rep=0, eta=0d 0h 0m 48s \n",
      "{'fold': 7, 'repeat': 0, 'n': 23, 'd': 2, 'mse': 0.22581282258033752, 'train_time': 14.071898718946613, 'prior_train_nmll': 1.432175636291504, 'train_nll': 17.55820655822754, 'test_nll': 1.8668408393859863, 'train_mse': 0.21040408313274384, 'state_dict_file': 'model_state_dict_-5094700764478834962.pkl'}\n",
      "2019-03-16 15:05:12.826049, fold=7, rep=1, eta=0d 0h 0m 39s \n",
      "{'fold': 7, 'repeat': 1, 'n': 23, 'd': 2, 'mse': 0.2091527283191681, 'train_time': 11.731153319007717, 'prior_train_nmll': 1.4728076457977295, 'train_nll': 18.197843551635742, 'test_nll': 1.8587431907653809, 'train_mse': 0.21883925795555115, 'state_dict_file': 'model_state_dict_-9199351250203808717.pkl'}\n",
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 8, 'n': 23, 'd': 2}\n",
      "errors:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'Traceback (most recent call last):\\n  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\\n    **training_options)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\\n    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\\n    test_outputs = model(testX)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\\n    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\\n  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\\n    res = test_train_covar.matmul(precomputed_cache)\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\\n    func = Matmul(self.representation_tree())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\\n    return LazyTensorRepresentationTree(self.evaluate_kernel())\\n  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\\n    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\\n    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\\n    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\\n  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\\n    outputs = self.forward(*inputs, **kwargs)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\\n    x1_projections = self._project(x1)\\n  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\\n    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\\nRuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\\n', 'fold': 9, 'n': 23, 'd': 2}\n",
      "errors:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/rp_experiments.py\", line 138, in run_experiment\n",
      "    **training_options)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 263, in train_additive_rp_gp\n",
      "    return train_exact_gp(trainX, trainY, testX, testY, rp=True, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/training_routines.py\", line 246, in train_exact_gp\n",
      "    test_outputs = model(testX)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_gp.py\", line 276, in __call__\n",
      "    predictive_mean = self.prediction_strategy.exact_predictive_mean(test_mean, test_train_covar)\n",
      "  File \"/home/ian/gpytorch/gpytorch/models/exact_prediction_strategies.py\", line 291, in exact_predictive_mean\n",
      "    res = test_train_covar.matmul(precomputed_cache)\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_tensor.py\", line 806, in matmul\n",
      "    func = Matmul(self.representation_tree())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 238, in representation_tree\n",
      "    return LazyTensorRepresentationTree(self.evaluate_kernel())\n",
      "  File \"/home/ian/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\", line 199, in evaluate_kernel\n",
      "    x1, x2, diag=False, batch_dims=self.batch_dims, **self.params\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/scale_kernel.py\", line 94, in forward\n",
      "    orig_output = self.base_kernel(x1, x2, diag=diag, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/kernels/kernel.py\", line 384, in __call__\n",
      "    res = super(Kernel, self).__call__(x1_, x2_, batch_dims=batch_dims, **params)\n",
      "  File \"/home/ian/gpytorch/gpytorch/module.py\", line 20, in __call__\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 91, in forward\n",
      "    x1_projections = self._project(x1)\n",
      "  File \"/home/ian/Documents/Research/Scalable_GPs/gp_helpers.py\", line 70, in _project\n",
      "    linear_projection = x.matmul(self.Ws[j]) + self.bs[j].unsqueeze(0)\n",
      "RuntimeError: invalid argument 13: ldc should be at least max(1, m=0), but have 0 at /opt/conda/conda-bld/pytorch-nightly_1551935369666/work/aten/src/TH/generic/THBlas.cpp:334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 15:08:25.327567, fold=0, rep=0, eta=0d 0h 5m 40s \n",
      "{'fold': 0, 'repeat': 0, 'n': 100, 'd': 7, 'mse': 1.4536058902740479, 'train_time': 17.900123110972345, 'prior_train_nmll': 1.0528591871261597, 'train_nll': -1.2246627807617188, 'test_nll': 31.79458236694336, 'train_mse': 0.0164335910230875, 'state_dict_file': 'model_state_dict_2735516277037853461.pkl'}\n",
      "2019-03-16 15:08:45.384507, fold=0, rep=1, eta=0d 0h 5m 41s \n",
      "{'fold': 0, 'repeat': 1, 'n': 100, 'd': 7, 'mse': 1.2620031833648682, 'train_time': 20.056727370945737, 'prior_train_nmll': 1.0191502571105957, 'train_nll': -6.0626678466796875, 'test_nll': 29.829910278320312, 'train_mse': 0.013760607689619064, 'state_dict_file': 'model_state_dict_3885118029543572562.pkl'}\n",
      "2019-03-16 15:08:57.628880, fold=1, rep=0, eta=0d 0h 4m 44s \n",
      "{'fold': 1, 'repeat': 0, 'n': 100, 'd': 7, 'mse': 1.1141897439956665, 'train_time': 12.241445621009916, 'prior_train_nmll': 1.0472252368927002, 'train_nll': 19.362468719482422, 'test_nll': 20.233734130859375, 'train_mse': 0.03740076348185539, 'state_dict_file': 'model_state_dict_-665659854449504531.pkl'}\n",
      "2019-03-16 15:09:14.573136, fold=1, rep=1, eta=0d 0h 4m 28s \n",
      "{'fold': 1, 'repeat': 1, 'n': 100, 'd': 7, 'mse': 1.4251911640167236, 'train_time': 16.944036686909385, 'prior_train_nmll': 1.0802438259124756, 'train_nll': 21.08556365966797, 'test_nll': 20.468101501464844, 'train_mse': 0.0377255342900753, 'state_dict_file': 'model_state_dict_4170868110569443453.pkl'}\n",
      "2019-03-16 15:09:29.448768, fold=2, rep=0, eta=0d 0h 4m 6s \n",
      "{'fold': 2, 'repeat': 0, 'n': 100, 'd': 7, 'mse': 1.6070430278778076, 'train_time': 14.872497632051818, 'prior_train_nmll': 0.9888104796409607, 'train_nll': 17.6124267578125, 'test_nll': 30.117900848388672, 'train_mse': 0.03714125603437424, 'state_dict_file': 'model_state_dict_2075754474969790559.pkl'}\n"
     ]
    }
   ],
   "source": [
    "options = dict(verbose=False, ard=False, activation=None, optimizer='adam',\n",
    "               n_epochs=1000, lr=0.1, patience=20, k=1, J=20, smooth=True, \n",
    "               noise_prior=True, learn_weights=True)\n",
    "datasets = rp_experiments.get_small_datasets() + rp_experiments.get_medium_datasets()\n",
    "for dataset in datasets:\n",
    "    with gpytorch.settings.cg_tolerance(0.01):\n",
    "        result = rp_experiments.run_experiment(training_routines.train_additive_rp_gp, options, \n",
    "                                     dataset=dataset, split=0.1, cv=True, repeats=2)\n",
    "    result['RP'] = True\n",
    "    result['k'] = 1\n",
    "    result['J'] = 10\n",
    "    result['dataset'] = dataset\n",
    "    result['options'] = json.dumps(options)\n",
    "    result['learn_weights'] = True\n",
    "    df = pd.concat([df, result])\n",
    "    df.to_csv('./learning_weights_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options = dict(verbose=False, rp=False, ard=False, activation=None, optimizer='adam',\n",
    "               n_epochs=1000, lr=0.1, patience=20, smooth=True, \n",
    "               noise_prior=True, additive=True)\n",
    "datasets = rp_experiments.get_small_datasets() + rp_experiments.get_medium_datasets()\n",
    "for dataset in datasets:\n",
    "    with gpytorch.settings.cg_tolerance(0.01):\n",
    "        result = rp_experiments.run_experiment(training_routines.train_exact_gp, options, \n",
    "                                     dataset=dataset, split=0.1, cv=True, repeats=2)\n",
    "    result['RP'] = False\n",
    "    results['additive'] = True\n",
    "    result['dataset'] = dataset\n",
    "    result['options'] = json.dumps(options)\n",
    "    df = pd.concat([df, result])\n",
    "    df.to_csv('./additive_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ski_options = dict(verbose=True, rp=True, ard=False, activation=None, optimizer='adam',\n",
    "                   n_epochs=1000, lr=0.1, patience=5, k=1, J=20, smooth=True, \n",
    "                   noise_prior=True, learn_weights=False, ski=True, grid_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_options = dict(verbose=True, rp=True, ard=False, activation=None, optimizer='adam',\n",
    "                   n_epochs=1000, lr=0.1, patience=5, k=1, J=20, smooth=True, \n",
    "                   noise_prior=True, learn_weights=False, ski=False, grid_size=None,\n",
    "                   batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_rbf_options = dict(verbose=True, rp=False, ard=False, activation=None, optimizer='adam',\n",
    "                   n_epochs=1000, lr=0.1, patience=5, smooth=True, \n",
    "                   noise_prior=True, ski=False, grid_size=None,\n",
    "                   batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['gas', 'skillcraft', 'sml', 'parkinsons', 'pumadyn32nm',   # \"medium\"\n",
    "            'pol', 'elevators', 'bike', 'kin40k', 'protein', ]  # small ones of the big ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin dataset  gas\n",
      "Begin with SKI\n",
      "epoch 0, loss 0.9470622539520264\n",
      "epoch 1, loss 0.9083818793296814\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2b81b45540ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         result = rp_experiments.run_experiment(\n\u001b[1;32m      7\u001b[0m             \u001b[0mtraining_routines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exact_gp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mski_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             dataset=dataset, split=0.2, cv=True, repeats=1)\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RP'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/Scalable_GPs/rp_experiments.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(training_routine, training_options, dataset, split, cv, addl_metrics, repeats, error_repeats)\u001b[0m\n\u001b[1;32m    136\u001b[0m                     ret = training_routine(trainX, trainY, testX,\n\u001b[1;32m    137\u001b[0m                                                             \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                                                             **training_options)\n\u001b[0m\u001b[1;32m    139\u001b[0m                     \u001b[0mmodel_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/Scalable_GPs/training_routines.py\u001b[0m in \u001b[0;36mtrain_exact_gp\u001b[0;34m(trainX, trainY, testX, testY, rp, k, J, ard, activation, optimizer, n_epochs, lr, verbose, patience, smooth, noise_prior, ski, grid_ratio, grid_size, learn_weights)\u001b[0m\n\u001b[1;32m    196\u001b[0m                          \u001b[0misloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                          smooth=smooth)\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mlikelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/Scalable_GPs/gp_helpers.py\u001b[0m in \u001b[0;36mtrain_to_convergence\u001b[0;34m(model, xs, ys, optimizer, lr, objective, max_iter, verbose, patience, conv_tol, check_conv, smooth, isloss, batch_size)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch {}, iter {}, loss {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/GPyTorchEnv2/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/Scalable_GPs/gp_helpers.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output, target, *params)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Add terms for SGPR / when inducing points are learned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Get log determininat and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mprobe_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobe_vectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mprobe_vector_norms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobe_vector_norms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         )(*args)\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minv_quad_term\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce_inv_quad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/functions/_inv_quad_log_det.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdet\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_logdet_forward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0msolves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_random_probes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, rhs, preconditioner, num_tridiag)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_cg_iterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mmax_tridiag_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_lanczos_quadrature_iterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mpreconditioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         )\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/utils/linear_cg.py\u001b[0m in \u001b[0;36mlinear_cg\u001b[0;34m(matmul_closure, rhs, n_tridiag, tolerance, eps, stop_updating_after, max_iter, max_tridiag_iter, initial_guess, preconditioner)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# Get next alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# alpha_{k} = (residual_{k-1}^T precon_residual{k-1}) / (p_vec_{k-1}^T mat p_vec_{k-1})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mmvms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_conjugate_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprecond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_conjugate_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmul_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         return torch.addcmul(\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mrhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/lazy/constant_mul_lazy_tensor.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_lazy_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanded_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/lazy/sum_lazy_tensor.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlazy_tensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_quad_form_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/lazy/sum_lazy_tensor.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlazy_tensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_quad_form_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpytorch/gpytorch/lazy/interpolated_lazy_tensor.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# left_interp * base_lazy_tensor * right_interp^T * rhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mleft_interp_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_interp_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbdsmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_interp_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with gpytorch.settings.cg_tolerance(0.01):\n",
    "    for dataset in datasets:\n",
    "        print(\"Begin dataset \", dataset)\n",
    "        # with SKI\n",
    "        print(\"Begin with SKI\")\n",
    "        result = rp_experiments.run_experiment(\n",
    "            training_routines.train_exact_gp, ski_options, \n",
    "            dataset=dataset, split=0.2, cv=True, repeats=1)\n",
    "        result['RP'] = True\n",
    "        result['k'] = 1\n",
    "        result['J'] = 20\n",
    "        result['dataset'] = dataset\n",
    "        result['scalable_method'] = 'ski'\n",
    "        result['options'] = json.dumps(ski_options)\n",
    "        \n",
    "        df = pd.concat([df, result])\n",
    "        df.to_csv('./scalable_methods_results.csv')\n",
    "        \n",
    "        # with SVI\n",
    "        print(\"Begin with SVI\")\n",
    "        result = rp_experiments.run_experiment(\n",
    "            training_routines.train_svi_gp, svi_options, \n",
    "            dataset=dataset, split=0.2, cv=True, repeats=1)\n",
    "        result['RP'] = True\n",
    "        result['k'] = 1\n",
    "        result['J'] = 20\n",
    "        result['dataset'] = dataset\n",
    "        result['scalable_method'] = 'SVI'\n",
    "        result['options'] = json.dumps(svi_options)\n",
    "        \n",
    "        df = pd.concat([df, result])\n",
    "        df.to_csv('./scalable_methods_results.csv')\n",
    "        \n",
    "        # with SVI + RBF Kernel\n",
    "        print(\"Begin with RBF SVI\")\n",
    "        result = rp_experiments.run_experiment(\n",
    "            training_routines.train_svi_gp, svi_rbf_options, \n",
    "            dataset=dataset, split=0.2, cv=True, repeats=1)\n",
    "        result['RP'] = False\n",
    "        result['k'] = 1\n",
    "        result['J'] = 20\n",
    "        result['dataset'] = dataset\n",
    "        result['scalable_method'] = 'SVI'\n",
    "        result['options'] = json.dumps(svi_rbf_options)\n",
    "        \n",
    "        df = pd.concat([df, result])\n",
    "        df.to_csv('./scalable_methods_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
